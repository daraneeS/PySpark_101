{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2c92f9",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=6cM5rmNGGYs\n",
    "- https://soumilshah1995.blogspot.com/2021/09/pyspark-crash-course-learn-pyspark-in.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237908aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all modules are ok ...... \n",
      "22/10/09 08:24:54 WARN Utils: Your hostname, Daranees-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.4.20 instead (on interface en0)\n",
      "22/10/09 08:24:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/09 08:24:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.4.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MyProcess</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8bb8cf94f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    from pyspark.sql.functions import filter\n",
    "    from pyspark.sql.types import *\n",
    "    from pyspark.sql.functions import udf\n",
    "    from pyspark.sql.types import StringType, FloatType, StructType, StructField\n",
    "    from IPython.core.display import Image, display\n",
    "    print(\"all modules are ok ...... \")\n",
    "    \n",
    "except Exception as e:\n",
    "    \n",
    "    print(\"some modules are missing : {} \".format(e))\n",
    "\n",
    "    \n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"MyProcess\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8226cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = map(lambda r: (r[0], r[1], float(r[2])),\n",
    "  map(lambda x: x.split(\",\"),\n",
    "    [\"Paris,Food,19.00\", \"Marseille,Clothing,12.00\",\n",
    "     \"Paris,Food,8.00\", \"Paris,Clothing,15.00\",\n",
    "     \"Marseille,Food,20.00\", \"Lyon,Book,10.00\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e08cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"city\",  StringType(), nullable=True),\n",
    "    StructField(\"type\",  StringType(), nullable=True),\n",
    "    StructField(\"price\", FloatType(),  nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97aa91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae72193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|     city|    type|price|\n",
      "+---------+--------+-----+\n",
      "|    Paris|    Food| 19.0|\n",
      "|Marseille|Clothing| 12.0|\n",
      "|    Paris|    Food|  8.0|\n",
      "|    Paris|Clothing| 15.0|\n",
      "|Marseille|    Food| 20.0|\n",
      "|     Lyon|    Book| 10.0|\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f63ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='Paris', type='Food', price=19.0),\n",
       " Row(city='Marseille', type='Clothing', price=12.0),\n",
       " Row(city='Paris', type='Food', price=8.0),\n",
       " Row(city='Paris', type='Clothing', price=15.0),\n",
       " Row(city='Marseille', type='Food', price=20.0),\n",
       " Row(city='Lyon', type='Book', price=10.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Collect() – Retrieve data from Spark RDD/DataFrame\"\"\"\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c49ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='Paris', type='Food', price=19.0),\n",
       " Row(city='Marseille', type='Clothing', price=12.0),\n",
       " Row(city='Paris', type='Food', price=8.0),\n",
       " Row(city='Paris', type='Clothing', price=15.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Returns the first n rows in the DataFrame.\"\"\"\n",
    "df.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b486c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='Paris', type='Food', price=19.0),\n",
       " Row(city='Marseille', type='Clothing', price=12.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"gets the first two values \"\"\"\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa1c549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='Marseille', type='Food', price=20.0),\n",
       " Row(city='Lyon', type='Book', price=10.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tails gets the Last values \"\"\"\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fca1eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     City|\n",
      "+---------+\n",
      "|    Paris|\n",
      "|Marseille|\n",
      "+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"selecting single column\"\"\"\n",
    "df.select(\"City\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0daf634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|     city|    type|\n",
      "+---------+--------+\n",
      "|    Paris|    Food|\n",
      "|Marseille|Clothing|\n",
      "+---------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"selecting multiplke column\"\"\"\n",
    "df.select([\"city\", \"type\"]).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0cbd2c",
   "metadata": {},
   "source": [
    "**filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4f76b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+\n",
      "| city|    type|price|\n",
      "+-----+--------+-----+\n",
      "|Paris|    Food| 19.0|\n",
      "|Paris|    Food|  8.0|\n",
      "|Paris|Clothing| 15.0|\n",
      "+-----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.city == \"Paris\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72243658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| city|type|price|\n",
      "+-----+----+-----+\n",
      "|Paris|Food| 19.0|\n",
      "|Paris|Food|  8.0|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.city == \"Paris\").filter(df.type == \"Food\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c56416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| city|type|price|\n",
      "+-----+----+-----+\n",
      "|Paris|Food| 19.0|\n",
      "|Paris|Food|  8.0|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\n",
    "    (df.city == \"Paris\") & (df.type == \"Food\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19977a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| city|\n",
      "+-----+\n",
      "|Paris|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\n",
    "    (df.city == \"Paris\") & (df.price > 18.0) ).select('city').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7358682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|price|\n",
      "+-----+\n",
      "|  8.0|\n",
      "| 10.0|\n",
      "| 12.0|\n",
      "| 15.0|\n",
      "| 19.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.price < 20 ).orderBy(df.price.asc()).select(\"price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe29e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|price|\n",
      "+-----+\n",
      "|  8.0|\n",
      "| 10.0|\n",
      "| 12.0|\n",
      "| 15.0|\n",
      "| 19.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.price < 20 ).sort(df.price.asc()).select(\"price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4fa0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|     city|    type|price|\n",
      "+---------+--------+-----+\n",
      "|    Paris|    Food| 19.0|\n",
      "|Marseille|Clothing| 12.0|\n",
      "+---------+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a064db",
   "metadata": {},
   "source": [
    "**Add New Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d0d088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+---------+\n",
      "|     city|    type|price|50percent|\n",
      "+---------+--------+-----+---------+\n",
      "|    Paris|    Food| 19.0|      9.5|\n",
      "|Marseille|Clothing| 12.0|      6.0|\n",
      "|    Paris|    Food|  8.0|      4.0|\n",
      "|    Paris|Clothing| 15.0|      7.5|\n",
      "|Marseille|    Food| 20.0|     10.0|\n",
      "|     Lyon|    Book| 10.0|      5.0|\n",
      "+---------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"50percent\", df.price / 2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e4e58",
   "metadata": {},
   "source": [
    "**Drop Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670e1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     city|price|\n",
      "+---------+-----+\n",
      "|    Paris| 19.0|\n",
      "|Marseille| 12.0|\n",
      "|    Paris|  8.0|\n",
      "|    Paris| 15.0|\n",
      "|Marseille| 20.0|\n",
      "|     Lyon| 10.0|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.type).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be114c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|type|\n",
      "+----+\n",
      "|Food|\n",
      "|Food|\n",
      "|Food|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(*[\"city\", \"price\"])\\\n",
    "  .filter(df.type == \"Food\")\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90707c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458fc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7193b81b",
   "metadata": {},
   "source": [
    "**rename column(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1f6fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|     CITY|    type|price|\n",
      "+---------+--------+-----+\n",
      "|    Paris|    Food| 19.0|\n",
      "|Marseille|Clothing| 12.0|\n",
      "|    Paris|    Food|  8.0|\n",
      "|    Paris|Clothing| 15.0|\n",
      "|Marseille|    Food| 20.0|\n",
      "|     Lyon|    Book| 10.0|\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"city\", \"CITY\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2339f",
   "metadata": {},
   "source": [
    "**Applying Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1dbbf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city', 'string'), ('type', 'string'), ('price', 'float')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07536113",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"string\")\n",
    "def to_string(price):\n",
    "    return str(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2aa8b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|PRICE_String|\n",
      "+------------+\n",
      "|        19.0|\n",
      "|        12.0|\n",
      "|         8.0|\n",
      "|        15.0|\n",
      "|        20.0|\n",
      "|        10.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    to_string(df.price).alias('PRICE_String')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "849693b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRICE_String', 'string')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price_string = df.select(to_string(df.price).alias('PRICE_String'))\n",
    "df_price_string.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1889d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"float\")\n",
    "def to_float(price):\n",
    "    return float(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f89ed555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|PRICE_Float|\n",
      "+-----------+\n",
      "|       19.0|\n",
      "|       12.0|\n",
      "|        8.0|\n",
      "|       15.0|\n",
      "|       20.0|\n",
      "|       10.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    to_float(df.price).alias('PRICE_Float')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32196f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRICE_Float', 'float')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price_float = df.select(to_float(df.price).alias('PRICE_Float'))\n",
    "df_price_float.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e233178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city', 'string'), ('type', 'string'), ('price', 'float')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dfca66",
   "metadata": {},
   "source": [
    "**Say i want to return JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d6726f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|     city|    type|price|\n",
      "+---------+--------+-----+\n",
      "|    Paris|    Food| 19.0|\n",
      "|Marseille|Clothing| 12.0|\n",
      "|    Paris|    Food|  8.0|\n",
      "|    Paris|Clothing| 15.0|\n",
      "|Marseille|    Food| 20.0|\n",
      "|     Lyon|    Book| 10.0|\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e385eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city', 'string'), ('type', 'string'), ('price', 'float')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a87a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_some_transformation(price):\n",
    "    if price < 15.0:\n",
    "        return {\"name\":\"value1\"}\n",
    "    else:\n",
    "        return {\"name\":\"value2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a4437cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "udfValueToCategoryGeo = udf(\n",
    "    to_some_transformation, \n",
    "    MapType(StringType(), StringType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8048c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+----------------+\n",
      "|     city|    type|price|             NEW|\n",
      "+---------+--------+-----+----------------+\n",
      "|    Paris|    Food| 19.0|{name -> value2}|\n",
      "|Marseille|Clothing| 12.0|{name -> value1}|\n",
      "|    Paris|    Food|  8.0|{name -> value1}|\n",
      "|    Paris|Clothing| 15.0|{name -> value2}|\n",
      "|Marseille|    Food| 20.0|{name -> value2}|\n",
      "|     Lyon|    Book| 10.0|{name -> value1}|\n",
      "+---------+--------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"NEW\", udfValueToCategoryGeo(\"price\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67c119",
   "metadata": {},
   "source": [
    "**Removing Null and Empty items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41447b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+\n",
      "| ID|FirstName|LastName|\n",
      "+---+---------+--------+\n",
      "|  1|    Navee|Srikanth|\n",
      "|  2|         |Srikanth|\n",
      "|  3|   Naveen|        |\n",
      "+---+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    [1,'Navee','Srikanth']\n",
    "    , [2,'','Srikanth'] ,\n",
    "    [3,'Naveen','']],\n",
    "    ['ID','FirstName','LastName']\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae1b8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+\n",
      "| ID|FirstName|LastName|\n",
      "+---+---------+--------+\n",
      "|  1|    Navee|Srikanth|\n",
      "|  2|         |Srikanth|\n",
      "|  3|   Naveen|        |\n",
      "+---+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ad0ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(x):\n",
    "    if x == '':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39dc6b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+--------+\n",
      "| ID|FirstName|LastName|category|\n",
      "+---+---------+--------+--------+\n",
      "|  1|    Navee|Srikanth|       0|\n",
      "|  3|   Naveen|        |       0|\n",
      "+---+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udfValueToCategory = udf(remove, IntegerType())\n",
    "df1 = df.withColumn(\"category\", udfValueToCategory(\"FirstName\"))\n",
    "df1.filter(df1.category == 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c795eda",
   "metadata": {},
   "source": [
    "**Aditional Resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1380bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"city\",  StringType(), nullable=True),\n",
    "    StructField(\"type\",  StringType(), nullable=True),\n",
    "    StructField(\"price\", FloatType(),  nullable=True)\n",
    "])\n",
    "\n",
    "data   = map(lambda r: (r[0], r[1], float(r[2])),\n",
    "  map(lambda x: x.split(\",\"),\n",
    "    [\"Paris,Food,19.00\", \"Marseille,Clothing,12.00\",\n",
    "     \"Paris,Food,8.00\", \"Paris,Clothing,15.00\",\n",
    "     \"Marseille,Food,20.00\", \"Lyon,Book,10.00\"]))\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "transactions = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09f7ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 8\n",
      "Partitioner: None\n",
      "Partitions structure: [[], [Row(city='Paris', type='Food', price=19.0)], [Row(city='Marseille', type='Clothing', price=12.0)], [Row(city='Paris', type='Food', price=8.0)], [], [Row(city='Paris', type='Clothing', price=15.0)], [Row(city='Marseille', type='Food', price=20.0)], [Row(city='Lyon', type='Book', price=10.0)]]\n"
     ]
    }
   ],
   "source": [
    "print('Number of partitions: {}'.format(transactions.rdd.getNumPartitions()))\n",
    "print('Partitioner: {}'.format(transactions.rdd.partitioner))\n",
    "print('Partitions structure: {}'.format(transactions.rdd.glom().collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cfc9de23",
   "metadata": {},
   "outputs": [],
   "source": [
    " from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e7d0689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://iamluminousmen-media.s3.amazonaws.com/media/spark-partitions/spark-partitions-2.jpg\" width=\"500\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://iamluminousmen-media.s3.amazonaws.com/media/spark-partitions/spark-partitions-2.jpg', width=500, unconfined=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dcb98",
   "metadata": {},
   "source": [
    "- Spark splits data in order to process it in parallel in memory.nce the user has submitted his job into the cluster, each partition is sent to a specific executor for further processing. Only one partition is processed by one executor at a time, so the size and number of partitions transferred to the executor are directly proportional to the time it takes to complete them. Thus the more partitions the more work is distributed to executors, with a smaller number of partitions the work will be done in larger pieces (and often faster).[2]\n",
    "\n",
    "\n",
    "- The most important reason is performance. By having all the data needed to calculate on a single node, we reduce the overhead on the shuffle (the need for serialization and network traffic).[2]\n",
    "\n",
    "\n",
    "- The second reason is the cost reduction — better utilization of the cluster will help to reduce idle resources.[2]\n",
    "\n",
    "\n",
    "What is Differnce between repartition and coalesce ?\n",
    "- repartition() specifies new number of partition, up or down\n",
    "- coalesce() uses existing partition, only decrease , no shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fe1b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.saveAsTextFile(path='./learn/test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55fa6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.repartition(2).saveAsTextFile(path='./learn/test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11c0b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.coalesce(1).saveAsTextFile(path='./learn/test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c662be98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./1.jpg\" width=\"200\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='./1.jpg', width=200, unconfined=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42e42a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|     city|    type|price|\n",
      "+---------+--------+-----+\n",
      "|    Paris|    Food| 19.0|\n",
      "|Marseille|Clothing| 12.0|\n",
      "|    Paris|    Food|  8.0|\n",
      "|    Paris|Clothing| 15.0|\n",
      "|Marseille|    Food| 20.0|\n",
      "|     Lyon|    Book| 10.0|\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445e45a",
   "metadata": {},
   "source": [
    "**iterating over all columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05a6ad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n",
      "Marseille\n",
      "Paris\n",
      "Paris\n",
      "Marseille\n",
      "Lyon\n"
     ]
    }
   ],
   "source": [
    "for x in df.rdd.collect():\n",
    "    print(x.city,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0525ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     city|avg(price)|\n",
      "+---------+----------+\n",
      "|    Paris|      14.0|\n",
      "|Marseille|      16.0|\n",
      "|     Lyon|      10.0|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"city\").mean(\"price\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0ad99",
   "metadata": {},
   "source": [
    "getting list of unique columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "100b92f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     city|\n",
      "+---------+\n",
      "|    Paris|\n",
      "|Marseille|\n",
      "|     Lyon|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"city\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf92f75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[city: string, type: string, price: float]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is dataframe object \"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a4ff579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[85] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is RDD object \"\"\"\n",
    "df.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5010532e",
   "metadata": {},
   "source": [
    "**Question**\n",
    "**What is difference betweeb RDD and Dataframe [4]**\n",
    "\n",
    "- So, a DataFrame has additional metadata due to its tabular format, which allows Spark to run certain optimizations on the finalized query.\n",
    "\n",
    "\n",
    "- An RDD, on the other hand, is merely a Resilient Distributed Dataset that is more of a blackbox of data that cannot be optimized as the operations that can be performed against it, are not as constrained.\n",
    "\n",
    "\n",
    "- However, you can go from a DataFrame to an RDD via its rdd method, and you can go from an RDD to a DataFrame (if the RDD is in a tabular format) via the toDF method\n",
    "\n",
    "\n",
    "- In general it is recommended to use a DataFrame where possible due to the built in query optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b87d87",
   "metadata": {},
   "source": [
    "**aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1a5029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|     city|count(1)|\n",
      "+---------+--------+\n",
      "|    Paris|       3|\n",
      "|Marseille|       2|\n",
      "|     Lyon|       1|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.city).agg({\"*\": \"count\"}).orderBy(\"city\",ascending=False ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4120b",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "[1] https://medium.com/@suci/running-pyspark-on-jupyter-notebook-with-docker-602b18ac4494\n",
    "\n",
    "[2] https://luminousmen.com/post/spark-partitions\n",
    "\n",
    "[3]https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html\n",
    "\n",
    "[4]https://stackoverflow.com/questions/31508083/difference-between-dataframe-dataset-and-rdd-in-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bc3cbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250a8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
